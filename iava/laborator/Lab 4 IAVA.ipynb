{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab04.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"6CbGAZP3h7SA"},"source":["#Laborator 4\n","\n","In cadrul acestui laborator o sa lucram cu blocurile de baza necesare construirii unor retele mai complexe. De interes sunt:\n","\n","\n","*   Residual Blocks\n","*   Inception Blocks\n","\n","Pe langa acestea, o sa aplicam si augmentari generale de date care au rolul de a face modelul robust la variatii mici. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"fjRY_xvrh_-L"},"source":["## Operatii Noi\n","\n","Urmatoarele operatii vor fi folosite in cadrul laboratorului\n","\n","Tensor shape: (batch,channels,dim1,dim2)\n","\n","\n","*  **torch.cat(tensors, dim=0).** Tensorii trebuie sa aiba aceleasi dim1,dim2, dar channels poate sa difere.\n","*  **torch.add(input, other)**. Tensorii trebuie sa aiba aceleasi dimensiune pe toate axele.\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pFmooG49iMjJ","outputId":"d11ef4ee-881b-4214-c2cc-176d8e8a1c33"},"source":["import numpy as np\n","import torch.nn as nn\n","import torch\n","\n","dummy_input_tensor1 = torch.rand((1,3,100,100))  # Input random de marime 100x100 cu 3 canale\n","dummy_input_tensor2 = torch.rand((1,5,100,100))  # Input random de marime 100x100 cu 5 canale\n","\n","# Normal se concateneaza pe dimensiunea canalelor.\n","x = torch.cat([dummy_input_tensor1,dummy_input_tensor2],dim=1) \n","print(x.shape) # Numarul de canele_output = canale_input2 + canale_input1\n","\n","dummy_input_tensor1 = torch.rand((1,3,100,100))  # Input random de marime 100x100 cu 3 canale\n","dummy_input_tensor2 = torch.rand((1,3,100,100))  # Input random de marime 100x100 cu 3 canale\n","\n","x = torch.add(dummy_input_tensor1,dummy_input_tensor2)\n","print(x.shape) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([1, 8, 100, 100])\n","torch.Size([1, 3, 100, 100])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"J2WG8tGsigqv"},"source":["##Residual Block\n","\n","In cadrul Resnet se utilizeaza residual connections / skip connections, care impreuna cu un path normal, ca cele implementate pana acum, formeaza un residual block. \n","\n","![resnetBlock](https://drive.google.com/uc?id=1fa4uuMBY4qmDbk4Tanu3CT-1E4nYq_He)\n","\n","###Cerinta 1 - **(3p)**\n","\n","Implementati ResidualBlock. Acesta duce input tensor in ($c_{input}$,width,height) in  ($c_{out}$,width,height) sau  ($c_{out}$,width/2,height/2) in functie de stride.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"khl9s7yHiycA"},"source":["import numpy as np\n","import torch.nn as nn\n","import torch\n","import torch.nn.functional as F\n","\n","class ResidualBlock(nn.Module):\n","  def __init__(self,input_channels=32,hidden_channels=64,output_channels=64,kernel_size=3,stride=1,activation=nn.ReLU()):\n","    super(ResidualBlock,self).__init__()\n","    layers = []\n","    # Your code here\n","\n","    self.net_normal = nn.Sequential(*layers)\n","\n","    self.net_residual = nn.Conv2d(input_channels,output_channels,1,stride)\n","\n","  def forward(self,x):\n","    x = torch.add(self.net_normal(x),self.net_residual(x))\n","    x = F.relu(x)\n","    return x\n","\n","block = ResidualBlock(3,64,128,3,2,nn.ReLU())\n","x = torch.rand(size=(1,3,100,100))\n","\n","# Should output torch.Size([1, 256, 50, 50])\n","print(block(x).shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZALBMSmPjWSJ"},"source":["##Inception Block\n","\n","In cadrul GoogleNet/InceptionNet este folosit Inception Block, care este alcatuit din mai multe mini-retele putin diferite, care se unesc la finalul Inception Block\n","\n","### Cerinta 2 - **(3p)**\n","\n","Implementati Inception Block. Acesta trebuie sa duca un Tensor ($ch_{input}$,w,h) in ($ch_{out}$,w/2,h/2)\n","\n","![InceptionBlock](https://drive.google.com/uc?id=1OOLqfHZSIdQp6xO1T8cUpgjmfkMgGDuU)"]},{"cell_type":"code","metadata":{"id":"e-23isTujgZd"},"source":["import numpy as np\n","import torch.nn as nn\n","import torch\n","import torch.nn.functional as F\n","\n","\n","class InceptionBlock(nn.Module):\n","  def __init__(self,input_channels=32,kernel_size=3,stride=1,activation=nn.ReLU()):\n","    super(InceptionBlock,self).__init__()\n","    ## De sters\n","    layers = []\n","    # Your code here\n","    self.path1 = nn.Sequential(*layers)\n","\n","    layers = []\n","    # Your code here\n","    self.path2 = nn.Sequential(*layers)\n","\n","    layers = []\n","    # Your code here\n","    self.path3 = nn.Sequential(*layers)\n","\n","    layers = []\n","    # Your code here\n","    self.path4 = nn.Sequential(*layers)\n","\n","  def forward(self,x):\n","    x1 = self.path1(x)\n","    print(x1.shape)\n","    x2 =self.path2(x)\n","    print(x2.shape)\n","    x3 =self.path3(x)\n","    print(x3.shape)\n","    x4 =self.path4(x)\n","    print(x4.shape)\n","    x = torch.cat([x1,x2,x3,x4],1)\n","    return x\n","\n","block = InceptionBlock(64,3,2,nn.ReLU())\n","x = torch.rand(size=(1,64,100,100))\n","\n","# Should output torch.Size([1, 128, 50, 50])\n","print(block(x).shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gk9ywDmWtLdh"},"source":["## Instantierea seturilor de date\n","\n","In acest laborator lucram cu un nou set de date. Este vorba de un dataset folosit in [aceasta competitie Kaggle](https://www.kaggle.com/c/dogs-vs-cats/overview), Pisici vs Caini. \n","\n","***In this competition, you'll write an algorithm to classify whether images contain either a dog or a cat.  This is easy for humans, dogs, and cats. Your computer will find it a bit more difficult.***\n"]},{"cell_type":"markdown","metadata":{"id":"BLxAdvGstEZH"},"source":["# Descarcarea setului de date\n","\n","### Authenticating with Kaggle using kaggle.json\n","\n","Navigate to https://www.kaggle.com. Then go to the [Account tab of your user profile](https://www.kaggle.com/me/account) and select Create API Token. This will trigger the download of kaggle.json, a file containing your API credentials.\n","\n","Then run the cell below to upload kaggle.json to your Colab runtime.\n"]},{"cell_type":"code","metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":89},"id":"vLT5e1cPuC0s","outputId":"f54a3050-caf6-4b0f-c26c-3691372f3be3"},"source":["from google.colab import files\n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))\n","  \n","# Then move kaggle.json into the folder where the API expects to find it.\n","!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-b936e81a-fc86-4500-91b8-40902bdc902c\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-b936e81a-fc86-4500-91b8-40902bdc902c\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving kaggle.json to kaggle.json\n","User uploaded file \"kaggle.json\" with length 69 bytes\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6bmCpT95vnnr"},"source":["!pip install kaggle\n","!kaggle competitions download -c dogs-vs-cats\n","!for z in *.zip; do unzip \"$z\"; done\n","!ls "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XpV6bzFhwcVK"},"source":["## Crearea Dataloader-ului\n","\n","In continuare, pentru a incarca date, sa o folosim un obiect mai complex, un Torch.utils.data.Dataset. Acesta are 3 functii importante:\n","\n","\n","*   __init__()\n","*   ____len____()\n","*  ____get_item____()\n","\n"]},{"cell_type":"code","metadata":{"id":"07kUfSMQwdhR"},"source":["import torch as t\n","from PIL import Image\n","import numpy as np\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.transforms.functional import to_tensor, normalize\n","import random, os\n","random.seed(42)\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","\n","train_dir = '../data/train'\n","test_dir = '../data/test'\n","\n","class CatsDogsDataset(Dataset):\n","    def __init__(self, file_list, width=128, height=128, transform=None):\n","        self.file_list = file_list\n","        self.transform = transform\n","        self.img_size = (width, height)\n","        \n","    def __len__(self):\n","        return len(self.file_list)\n","    \n","    def __getitem__(self,idx):\n","        img_path = self.file_list[idx]\n","        img = Image.open(img_path)\n","\n","        original_width, original_height = img.size\n","\n","        img = img.resize(self.img_size)\n","        img = np.array(img)\n","        \n","        label = img_path.split('/')[-1].split('.')[0]\n","        if label == 'dog':\n","            label = 1\n","        elif label == 'cat':\n","            label = 0\n","            \n","        return to_tensor(img), label"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7jBnJQwi304r"},"source":["Construire Dataset si vizualizare date."]},{"cell_type":"code","metadata":{"id":"FfFoySuh32uy"},"source":["from IPython.display import clear_output\n","import time\n","\n","train_test_proportion = .85\n","\n","import glob\n","\n","samples = glob.glob(os.path.join('./train','*.jpg'))\n","random.shuffle(samples)\n","\n","train_samples = samples[:int(train_test_proportion*len(samples))]\n","test_samples = samples[int(train_test_proportion*len(samples)):]\n","\n","cats_dogs_train = CatsDogsDataset(train_samples)\n","cats_dogs_test = CatsDogsDataset(test_samples)\n","\n","train_loader = DataLoader(cats_dogs_train, batch_size=16, shuffle=True, num_workers=4)\n","test_loader = DataLoader(cats_dogs_test, batch_size=16, shuffle=False, num_workers=4)\n","\n","see_examples = 10\n","for i, (imgs, label) in enumerate(train_loader):\n","    clear_output(wait=True)\n","    plt.imshow(imgs[0])\n","    plt.text(5, 15, \"DOG\" if label[0] else \"CAT\", fontsize ='xx-large', color='red', fontweight='bold')\n","    plt.show()\n","\n","    if i >= see_examples - 1:\n","      break\n","    time.sleep(1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EU9ElphQuwmZ"},"source":["### Cerinta 3 - **(4p)**\n","\n","  1. Antrenati o retea convolutionala (o arhitectura la alegere din laboratorul 3) folosind acest dataset, pe GPU (https://pytorch.org/docs/stable/notes/cuda.html) **(1p)**\n","  2. Antrenati o retea de tip Resnet (folosind blocuri de tip Residual) **(1p)**\n","  3. Antrenati o retea de tip Inception (folosind blocuri de tip Inception)  **(1p)**\n","  4. Experimentati cu diferiti hyperparameters (numarul de layers, numarul de filtre/neuroni, etc.) **(1p)**\n"]}]}