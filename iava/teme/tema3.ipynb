{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tema3_Diaconu_Rebeca_333.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpoTZudv_LK5"
      },
      "source": [
        "## Straturi Noi\n",
        "\n",
        "In continuare o sa utilizam o parte din straturile prezentate in curs.\n",
        "\n",
        "Staturi noi:\n",
        "\n",
        "Layer Convolutional:\n",
        "* torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0)\n",
        "\n",
        "Layere Pooling:\n",
        "* torch.nn.MaxPool2d(kernel_size, stride=None, padding=0)\n",
        "* torch.nn.AveragePool2d(kernel_size, stride=None, padding=0)\n",
        "\n",
        "Layere Adaptive Pool, intalnit adesea si ca Global Pool:\n",
        "* torch.nn.AdaptiveAvgPool2d(output_size)\n",
        "* torch.nn.AdaptiveMaxPool2d(output_size)\n",
        "\n",
        "Layer de liniarizare:\n",
        "\n",
        "* torch.nn.Flatten()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HWqK9mqHxgB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad5c1328-bb3f-4d01-b75d-f98f23c1ed8d"
      },
      "source": [
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "dummy_input_tensor = torch.rand((1,3,100,100))  # Input random de marime 100x100 cu 3 canale\n",
        "\n",
        "layer = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(3,3), stride=(2,2))\n",
        "print(\"Conv1 result shape\",layer(dummy_input_tensor).shape)\n",
        "\n",
        "layer = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(13,13), stride=(2,2))\n",
        "print(\"Conv2 result shape\",layer(dummy_input_tensor).shape)\n",
        "\n",
        "layer = nn.MaxPool2d(kernel_size=(3,3)) # Stride este inferat din kernel size, ca fiind egal cu kernel size ca sa nu repete elementele luate\n",
        "print(\"Pool result shape\",layer(dummy_input_tensor).shape)\n",
        "\n",
        "# Utilizate pentru a reduce dimensiunea la una prestabilita, util cand marimea input ului este variabil\n",
        "layer = nn.AdaptiveAvgPool2d(output_size=(5,5))\n",
        "print(\"Global Pool result shape\",layer(dummy_input_tensor).shape)\n",
        "\n",
        "layer = nn.Flatten()\n",
        "print(\"Flaten result shape\",layer(dummy_input_tensor).shape)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Conv1 result shape torch.Size([1, 10, 49, 49])\n",
            "Conv2 result shape torch.Size([1, 10, 44, 44])\n",
            "Pool result shape torch.Size([1, 3, 33, 33])\n",
            "Global Pool result shape torch.Size([1, 3, 5, 5])\n",
            "Flaten result shape torch.Size([1, 30000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOTmqyCxJ3fk"
      },
      "source": [
        "### Exercitiul 1\n",
        "\n",
        "**(1p)** Utilizati o serie de Conv2D/Pool2D pentru a ajunge la urmatoarele marimi plecand de la input 3x100x100:\n",
        "*   [1, 10, 24, 24]\n",
        "*   [1, 10, 9, 9]\n",
        "*  [1, 3, 2, 2]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HtEeXbeKeKu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cbe35e1-db0c-4a9e-b99e-a4e3bb988f78"
      },
      "source": [
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "dummy_input_tensor = torch.rand((1,3,100,100))  # Input random de marime 100x100 cu 3 canale\n",
        "\n",
        "\n",
        "layer = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(54,54), stride=(2,2))\n",
        "print(\"Cerinta 1: \",layer(dummy_input_tensor).shape)\n",
        "\n",
        "\n",
        "layer = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(36, 36), stride=(8,8))\n",
        "print(\"Cerinta 2: \",layer(dummy_input_tensor).shape)\n",
        "\n",
        "layer = nn.AdaptiveAvgPool2d(output_size=(2,2))\n",
        "print(\"Cerinta 3: \", layer(dummy_input_tensor).shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cerinta 1:  torch.Size([1, 10, 24, 24])\n",
            "Cerinta 2:  torch.Size([1, 10, 9, 9])\n",
            "Cerinta 3:  torch.Size([1, 3, 2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvdPtetggm61"
      },
      "source": [
        "## Instantierea seturilor de date"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czyIhYt5gmUQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dd97300-27e1-4c0d-b73e-db5a6336cd65"
      },
      "source": [
        "import torchvision\n",
        "\n",
        "cifar_train = torchvision.datasets.CIFAR10(\"./data\", download=True)\n",
        "cifar_test = torchvision.datasets.CIFAR10(\"./data\", train=False)\n",
        "# print(cifar_train[0][0].size)\n"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOA4ted_hHdB"
      },
      "source": [
        "## Crearea Dataloader-ului\n",
        "\n",
        "### Exercitiul 2\n",
        " * **(2p)** Implementati functia de preprocesare a datelor, __preproc_fn(examples)__.\n",
        "\n",
        "\n",
        "Atentie! Spre deosebire de intrarea pentru retelele fully-connected, pentru retelele convolutionale intrearea nu trebuie liniarizata, ci doar normalizata.\n",
        "\n",
        "#### Hint\n",
        "\n",
        "  * Amintiti-va folosirea functiei __normalize__ din torchvision.transforms.functional din laboratorul trecut.\n",
        "  * Modificati functia *preproc_fn* din laboratorul trecut, pentru a normaliza datele in intervalul [-1, 1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGHfd229hRyR"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms.functional import to_tensor, normalize\n",
        "\n",
        "def preproc_fn(examples):\n",
        "  \n",
        "  processed_images = []\n",
        "  processed_labels = []\n",
        "\n",
        "  for example in examples:\n",
        "    tensor_image = to_tensor(example[0])\n",
        "    # In linia de mai jos imaginea este normalizata astfel incat sa aiba toate valorile in \n",
        "    # [-1, 1] in loc de [0, 255]\n",
        "    normalized_tensor_image = normalize(tensor_image, [0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "    normalized_tensor_image = normalized_tensor_image.unsqueeze(0)\n",
        "    processed_images.append(normalized_tensor_image)\n",
        "    \n",
        "    label = np.array(example[1])\n",
        "    tensor_label = torch.tensor(label)\n",
        "    tensor_label = tensor_label.unsqueeze(0)\n",
        "    processed_labels.append(tensor_label)\n",
        "\n",
        "  torch_images = torch.cat(processed_images, dim=0)\n",
        "  torch_labels = torch.cat(processed_labels, dim=0)\n",
        "\n",
        "  return (torch_images, torch_labels)\n",
        "\n",
        "train_loader = DataLoader(cifar_train, batch_size=500, shuffle=True, num_workers=2, collate_fn=preproc_fn)\n",
        "test_loader = DataLoader(cifar_test, batch_size=1, shuffle=False, collate_fn=preproc_fn)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnV6PIC1kQMi"
      },
      "source": [
        "## Crearea unei retele neurale convolutionale\n",
        "\n",
        "### Cerinte\n",
        " * **(1p)** Creati o clasa care mosteneste clasa nn.Module. Ea va reprezenta o retea neurala convolutionala pentru clasificare ale celor 10 clase din datasetul CIFAR10.\n",
        "    * Reteaua trebuie sa aiba 2 straturi convolutionale care sa reduca dimensiunea spatiala a imaginii de 2 ori\n",
        "    * Liniarizati iesirea din cel de-al doilea strat convolutional\n",
        "    * Adaugat stratul final de tipul 'fully-connected'\n",
        "    * Folositi o functie de activare la alegere\n",
        "\n",
        "#### Hint\n",
        "\n",
        "Pentru a liniariza iesirea din cel de-al doilea feature map puteti adopta mai multe strategii:\n",
        "  * Liniarizare prin schimbarea shape-ului la [batch_size, -1]\n",
        "  * Global Max Pooling si apoi liniarizare la [batch_size, -1]\n",
        "  * Average Max Pooling si apoi liniarizare la [batch_size, -1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1Ddc7D-lAEN"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "\n",
        "    super(Net, self).__init__()\n",
        "\n",
        "    self.layer1 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(3,3), stride=(2,2))\n",
        "    self.layer2 = nn.MaxPool2d(kernel_size=(15,15))\n",
        "    self.activation = nn.ReLU()\n",
        "\n",
        "  def forward(self,x):\n",
        "    output1 = self.activation(self.layer1(x))\n",
        "    output2 = self.activation(self.layer2(output1))\n",
        "    output = output2.reshape(output2.size(0), -1)\n",
        "\n",
        "    return output "
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK0Z9NeYTghv"
      },
      "source": [
        "## Definirea obiectelor folosite in timpul antrenarii\n",
        "\n",
        "### Cerinte **(1p)**\n",
        "  * Numarul de epoci\n",
        "  * Retea\n",
        "  * Optimizator\n",
        "  * Alegeti functia de cost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az3WKQdpod34"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Definiti numarul de epoci\n",
        "epochs = 30\n",
        "\n",
        "# Definiti reteaua\n",
        "network = Net()\n",
        "\n",
        "# Definiti optimizatorul\n",
        "optimizer = optim.SGD(network.parameters(), lr=1e-2)\n",
        "\n",
        "# Dupa definirea optimizatorului si dupa fiecare iteratie trebuie apelata functia zero_grad().\n",
        "# Aceasta face toti gradientii zero.\n",
        "# Completati codul pentru a face gradientii zero aici\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Definiti functia cost pentru clasificare Cross-Entropy\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAnUsWYWodb4"
      },
      "source": [
        "## Definirea functiei de antrenare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9MTYanoMZ8H"
      },
      "source": [
        "def train_fn(epochs: int, train_loader: DataLoader, test_loader: DataLoader, \n",
        "             net: nn.Module, loss_fn: nn.Module, optimizer: optim.Optimizer):\n",
        "  # Iteram prin numarul de epoci\n",
        "  for e in range(epochs):\n",
        "    \n",
        "    # Iteram prin fiecare exemplu din dataset\n",
        "    for images, labels in train_loader:\n",
        "\n",
        "      # Aplicam reteaua neurala pe imaginile de intrare\n",
        "      out = net(images)\n",
        "      # Aplicam functia cost pe iesirea retelei neurale si pe adnotarile imaginilor \n",
        "      loss = loss_fn(out, labels)\n",
        "      # Aplicam algoritmul de back-propagation\n",
        "      loss.backward()\n",
        "      # Facem pasul de optimizare, pentru a aplica gradientii pe parametrii retelei\n",
        "      optimizer.step()\n",
        "      # Apelam functia zero_grad() pentru a uita gradientii de la iteratie curenta\n",
        "      optimizer.zero_grad()\n",
        "    \n",
        "    print(\"Loss-ul la finalul epocii {} are valoarea {}\".format(e, loss.item()))\n",
        "\n",
        "    # Caluculul acuratetii\n",
        "    count = len(test_loader)\n",
        "    correct = 0\n",
        "\n",
        "    for test_image, test_label in test_loader:\n",
        "      out_class = torch.argmax(net(test_image))\n",
        "      if out_class == test_label:\n",
        "        correct += 1\n",
        "\n",
        "    print(\"Acuratetea la finalul epocii {} este {:.2f}%\".format(e, (correct / count) * 100))"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2QYb77CjlaN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "86408ee3-ee84-46f2-894e-1e72e8424859"
      },
      "source": [
        "train_fn(epochs, train_loader, test_loader, network, loss_fn, optimizer)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss-ul la finalul epocii 0 are valoarea 2.1542108058929443\n",
            "Acuratetea la finalul epocii 0 este 19.72%\n",
            "Loss-ul la finalul epocii 1 are valoarea 2.151982069015503\n",
            "Acuratetea la finalul epocii 1 este 19.67%\n",
            "Loss-ul la finalul epocii 2 are valoarea 2.1738314628601074\n",
            "Acuratetea la finalul epocii 2 este 19.82%\n",
            "Loss-ul la finalul epocii 3 are valoarea 2.171030044555664\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-146-f4676f147b19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-71-d7e4b3831ddc>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(epochs, train_loader, test_loader, net, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m       \u001b[0mout_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mout_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2695\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstrides\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tobytes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2697\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWvb00A-TkJq"
      },
      "source": [
        "\n",
        "## Antrenarea\n",
        "\n",
        "### Cerinte\n",
        "  * Antrenati reteaua definita mai sus (clasa Net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmVavwztTZkz"
      },
      "source": [
        "## Reteaua LeNet\n",
        "\n",
        "### Cerinte\n",
        "  * **(3p)** Implementati reteaua LeNet dupa figura de mai jos si antrenati-o\n",
        "\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1OVancUyIViMRMZdULFSVCvXJHQP0NGUV)\n",
        "\n",
        "Figura arhitectura LeNet\n",
        "\n",
        "![alt text](https://debuggercafe.com/wp-content/uploads/2019/07/Layers-in-LeNet.png)\n",
        "\n",
        "Tabel arhitectura LeNet\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoe1vbggO-4U"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LeNet, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1)\n",
        "    self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1)\n",
        "    self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "    self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1)\n",
        "    self.fc1 = nn.Linear(120,84)\n",
        "    self.fc2 = nn.Linear(84, 10)\n",
        "\n",
        "    self.tanh = nn.Tanh()\n",
        "    self.softmax = nn.Softmax()\n",
        "\n",
        "  def forward(self,x):\n",
        "    output1 = self.conv1(x)\n",
        "    out1 = self.tanh(output1)\n",
        "    output2 = self.pool1(out1)\n",
        "    out2 = self.tanh(output2)\n",
        "    output3 = self.conv2(out2)\n",
        "    out3 = self.tanh(output3)\n",
        "    output4 = self.pool2(out3)\n",
        "    out4 = self.tanh(output4)\n",
        "    output5 = self.conv3(out4)\n",
        "    out5 = self.tanh(output5)\n",
        "\n",
        "    out5 = torch.flatten(out5, 1)\n",
        "\n",
        "    linear1 = self.fc1(out5)\n",
        "    out6 = self.tanh(linear1)\n",
        "    linear2 = self.fc2(out6)\n",
        "\n",
        "    output = self.softmax(linear2)\n",
        "\n",
        "    return output\n",
        "  "
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0XPmGrEol9M"
      },
      "source": [
        "## Redefinirea obiectelor folosite in timpul antrenarii pentru reteaua LeNet\n",
        "\n",
        "### Cerinta\n",
        " * Redefiniti obiectele pentru a antrena reteaua LeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhqNoDmQo66c"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Definiti numarul de epoci\n",
        "epochs = 20\n",
        "\n",
        "# Definiti reteaua\n",
        "lenet = LeNet()\n",
        "\n",
        "# Definiti optimizatorul\n",
        "lenet_optimizer = optim.SGD(lenet.parameters(), lr=1e-2)\n",
        "# Dupa definirea optimizatorului si dupa fiecare iteratie trebuie apelata functia zero_grad().\n",
        "# Aceasta face toti gradientii zero.\n",
        "# Completati codul pentru a face gradientii zero aici\n",
        "lenet_optimizer.zero_grad()\n",
        "\n",
        "# Definiti functia cost pentru clasificare Cross-Entropy\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwIQwUQpo_eR"
      },
      "source": [
        "## Antrenarea retelei LeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUl8W42do_sL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dc2fc2a-c20c-4dfa-e76b-963bcc58a74f"
      },
      "source": [
        "train_fn(epochs, train_loader, test_loader, lenet, loss_fn, lenet_optimizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss-ul la finalul epocii 0 are valoarea 2.3028147220611572\n",
            "Acuratetea la finalul epocii 0 este 9.71%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OspDtfFnTodr"
      },
      "source": [
        "###Augmentare retea\n",
        "\n",
        "Reteaua de mai devreme duce lipsa de regularizare. O forma foarte puternica de regularizare este normalizarea, iar pentru acest lucru exista straturi speciale.\n",
        "\n",
        "Astfel de straturi:\n",
        "\n",
        "* torch.nn.BatchNorm2d(num_features)\n",
        "* torch.nn.InstanceNorm2d(num_features)\n",
        "\n",
        "Un alt element important il reprezinta functiile de activare, care pot influenta convergenta si puterea retelei. Cateva exemple de functii de activate:\n",
        "\n",
        "\n",
        "* Relu\n",
        "* Sigmoid\n",
        "* Tanh\n",
        "* LeakyRelu\n",
        "* GELU\n",
        "\n",
        "## Cerinta\n",
        "\n",
        "**(2p)** Experimentati cu aceste elemente in cadrul retelei LeNet definita mai devreme, pentru a obtine o acuratete mai buna. Observati viteza de convergenta si performanta retelei pentru 3 configuratii diferite.\n",
        "\n",
        "\n",
        "###Bonus\n",
        "**(1p)** Antrenati reteaua folosind GPU (Graphics processing unit)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n"
      ]
    }
  ]
}